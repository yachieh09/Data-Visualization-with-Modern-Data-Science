{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Visualization and Modern Data Science\n",
    "\n",
    "> Homework 2: Visualization and Modern Data Science, NTU, Spring, 2021.\n",
    "\n",
    "Kuo, Yao-Jen <yaojenkuo@ntu.edu.tw> from [DATAINPOINT](https://www.datainpoint.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "conn = sqlite3.connect('covid19.db')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to select all the columns and records from `daily_report`.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (3981, 7) result.\n",
    "\n",
    "```\n",
    "            Combined_Key          Last_Update  Confirmed  Deaths  Recovered  \\\n",
    "0            Afghanistan  2021-03-01 05:23:01      55714    2443      49333   \n",
    "1                Albania  2021-03-01 05:23:01     107167    1796      69773   \n",
    "2                Algeria  2021-03-01 05:23:01     113092    2983      78098   \n",
    "3                Andorra  2021-03-01 05:23:01      10866     110      10446   \n",
    "4                 Angola  2021-03-01 05:23:01      20807     508      19322   \n",
    "...                  ...                  ...        ...     ...        ...   \n",
    "3976             Vietnam  2021-03-01 05:23:01       2448      35       1876   \n",
    "3977  West Bank and Gaza  2021-03-01 05:23:01     183612    2042     166936   \n",
    "3978               Yemen  2021-03-01 05:23:01       2285     634       1435   \n",
    "3979              Zambia  2021-03-01 05:23:01      78534    1091      74498   \n",
    "3980            Zimbabwe  2021-03-01 05:23:01      36089    1463      32666   \n",
    "\n",
    "      Incident_Rate  Case_Fatality_Ratio  \n",
    "0        143.119379             4.384894  \n",
    "1       3723.921051             1.675889  \n",
    "2        257.900365             2.637676  \n",
    "3      14063.288682             1.012332  \n",
    "4         63.308070             2.441486  \n",
    "...             ...                  ...  \n",
    "3976       2.514933             1.429739  \n",
    "3977    3599.235977             1.112128  \n",
    "3978       7.661109            27.746171  \n",
    "3979     427.187706             1.389207  \n",
    "3980     242.812200             4.053867  \n",
    "\n",
    "[3981 rows x 7 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_all_from_daily_report =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select * \n",
    "from daily_report\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to select four variables from `daily_report` as specified.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (3981, 4) result.\n",
    "\n",
    "```\n",
    "            Combined_Key  Confirmed  Deaths  Recovered\n",
    "0            Afghanistan      55714    2443      49333\n",
    "1                Albania     107167    1796      69773\n",
    "2                Algeria     113092    2983      78098\n",
    "3                Andorra      10866     110      10446\n",
    "4                 Angola      20807     508      19322\n",
    "...                  ...        ...     ...        ...\n",
    "3976             Vietnam       2448      35       1876\n",
    "3977  West Bank and Gaza     183612    2042     166936\n",
    "3978               Yemen       2285     634       1435\n",
    "3979              Zambia      78534    1091      74498\n",
    "3980            Zimbabwe      36089    1463      32666\n",
    "\n",
    "[3981 rows x 4 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_variables_from_daily_report =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select Combined_Key, Confirmed, Deaths, Recovered\n",
    "From daily_report\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to find the records of Taiwan in `time_series`.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (404, 7) result.\n",
    "\n",
    "```\n",
    "    Province_State Country_Region        Date  Confirmed  Deaths  Daily_Cases  \\\n",
    "0           Taiwan         Taiwan  2020-01-22          1       0            1   \n",
    "1           Taiwan         Taiwan  2020-01-23          1       0            0   \n",
    "2           Taiwan         Taiwan  2020-01-24          3       0            2   \n",
    "3           Taiwan         Taiwan  2020-01-25          3       0            0   \n",
    "4           Taiwan         Taiwan  2020-01-26          4       0            1   \n",
    "..             ...            ...         ...        ...     ...          ...   \n",
    "399         Taiwan         Taiwan  2021-02-24        946       9            4   \n",
    "400         Taiwan         Taiwan  2021-02-25        951       9            5   \n",
    "401         Taiwan         Taiwan  2021-02-26        951       9            0   \n",
    "402         Taiwan         Taiwan  2021-02-27        954       9            3   \n",
    "403         Taiwan         Taiwan  2021-02-28        955       9            1   \n",
    "\n",
    "     Daily_Deaths  \n",
    "0               0  \n",
    "1               0  \n",
    "2               0  \n",
    "3               0  \n",
    "4               0  \n",
    "..            ...  \n",
    "399             0  \n",
    "400             0  \n",
    "401             0  \n",
    "402             0  \n",
    "403             0  \n",
    "\n",
    "[404 rows x 7 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_taiwan_from_time_series =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select *\n",
    "from time_series\n",
    "where Country_Region = 'Taiwan'\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to find the records of Taiwan and the day of \"+0\" in `time_series`, selecting specified variables.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (162, 3) result.\n",
    "\n",
    "```\n",
    "    Country_Region        Date  Daily_Cases\n",
    "0           Taiwan  2020-01-23            0\n",
    "1           Taiwan  2020-01-25            0\n",
    "2           Taiwan  2020-01-29            0\n",
    "3           Taiwan  2020-02-01            0\n",
    "4           Taiwan  2020-02-02            0\n",
    "..             ...         ...          ...\n",
    "157         Taiwan  2021-02-16            0\n",
    "158         Taiwan  2021-02-21            0\n",
    "159         Taiwan  2021-02-22            0\n",
    "160         Taiwan  2021-02-23            0\n",
    "161         Taiwan  2021-02-26            0\n",
    "\n",
    "[162 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_taiwan_plus_zero_from_time_series =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select Country_Region, Date, Daily_Cases\n",
    "from time_series\n",
    "where Country_Region = 'Taiwan' AND Daily_Cases = 0\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to find the records of US in `daily_report`, selecting specified variables.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (3274, 3) result.\n",
    "\n",
    "```\n",
    "                 Combined_Key  Confirmed  Deaths\n",
    "0        Autauga, Alabama, US       6264      91\n",
    "1        Baldwin, Alabama, US      19732     283\n",
    "2        Barbour, Alabama, US       2115      51\n",
    "3           Bibb, Alabama, US       2450      60\n",
    "4         Blount, Alabama, US       6097     127\n",
    "...                       ...        ...     ...\n",
    "3269       Teton, Wyoming, US       3351       9\n",
    "3270       Uinta, Wyoming, US       2053      12\n",
    "3271  Unassigned, Wyoming, US          0       0\n",
    "3272    Washakie, Wyoming, US        881      26\n",
    "3273      Weston, Wyoming, US        622       5\n",
    "\n",
    "[3274 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_us_from_daily_report =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select Combined_Key, Confirmed, Deaths\n",
    "from daily_report\n",
    "where Combined_Key LIKE '%, US'\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to find the records of US(`Country_Region` equals to US) in `lookup_table`.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (3404, 10) result.\n",
    "\n",
    "```\n",
    "           UID                  Combined_Key iso2 iso3 Country_Region  \\\n",
    "0          840                            US   US  USA             US   \n",
    "1           16            American Samoa, US   AS  ASM             US   \n",
    "2          316                      Guam, US   GU  GUM             US   \n",
    "3          580  Northern Mariana Islands, US   MP  MNP             US   \n",
    "4          850            Virgin Islands, US   VI  VIR             US   \n",
    "...        ...                           ...  ...  ...            ...   \n",
    "3399  84056037       Sweetwater, Wyoming, US   US  USA             US   \n",
    "3400  84056039            Teton, Wyoming, US   US  USA             US   \n",
    "3401  84056041            Uinta, Wyoming, US   US  USA             US   \n",
    "3402  84056043         Washakie, Wyoming, US   US  USA             US   \n",
    "3403  84056045           Weston, Wyoming, US   US  USA             US   \n",
    "\n",
    "                Province_State      Admin2        Lat       Long_   Population  \n",
    "0                         None        None  40.000000 -100.000000  329466283.0  \n",
    "1               American Samoa        None -14.271000 -170.132000      55641.0  \n",
    "2                         Guam        None  13.444300  144.793700     164229.0  \n",
    "3     Northern Mariana Islands        None  15.097900  145.673900      55144.0  \n",
    "4               Virgin Islands        None  18.335800  -64.896300     107268.0  \n",
    "...                        ...         ...        ...         ...          ...  \n",
    "3399                   Wyoming  Sweetwater  41.659439 -108.882788      42343.0  \n",
    "3400                   Wyoming       Teton  43.935225 -110.589080      23464.0  \n",
    "3401                   Wyoming       Uinta  41.287818 -110.547578      20226.0  \n",
    "3402                   Wyoming    Washakie  43.904516 -107.680187       7805.0  \n",
    "3403                   Wyoming      Weston  43.839612 -104.567488       6927.0  \n",
    "\n",
    "[3404 rows x 10 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_us_from_lookup_table =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select *\n",
    "from lookup_table\n",
    "where Country_Region = 'US'\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to aggregate the number of total confirmed, total deaths and total recovered worldwide as of 2021-02-28 in `daily_report`. Aliasing the column names as specified.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (1, 3) result.\n",
    "\n",
    "```\n",
    "   total_confirmed  total_deaths  total_recovered\n",
    "0        114177059       2532456         64418462\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregate_totals_from_daily_report =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select sum(confirmed) as total_confirmed, sum(deaths) as total_deaths, sum(recovered) as total_recovered\n",
    "from daily_report\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to extract the countries with province records in `time_series`. Sorting the result with ascending order.\n",
    "\n",
    "PS You may use the condition `Country_Region != Province_State`\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (7, 1) result.\n",
    "\n",
    "```\n",
    "  countries_with_province_record\n",
    "0                      Australia\n",
    "1                         Canada\n",
    "2                          China\n",
    "3                        Denmark\n",
    "4                         France\n",
    "5                    Netherlands\n",
    "6                 United Kingdom\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_countries_with_province_records_in_time_series =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select DISTINCT Country_Region AS countries_with_province_record\n",
    "from time_series\n",
    "where Country_Region != Province_State\n",
    "order by countries_with_province_record ASC\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to find the largest daily case for each country in `time_series`. Sorting the result with descending order.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (192, 3) result.\n",
    "\n",
    "```\n",
    "       Country_Region        Date  largest_daily_cases\n",
    "0              Turkey  2020-12-10               823225\n",
    "1                  US  2021-01-02               300416\n",
    "2              France  2020-11-02               104314\n",
    "3               India  2020-09-16                97894\n",
    "4               Spain  2021-01-25                93822\n",
    "..                ...         ...                  ...\n",
    "187   Solomon Islands  2020-11-02                    5\n",
    "188  Marshall Islands  2020-11-17                    3\n",
    "189        Micronesia  2021-01-21                    1\n",
    "190             Samoa  2020-11-18                    1\n",
    "191           Vanuatu  2020-11-10                    1\n",
    "\n",
    "[192 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_largest_daily_case_by_country_in_time_series =\\\n",
    "\"\"\"\n",
    "select Country_Region, Date, MAX(daily_cases) AS largest_daily_cases\n",
    "from time_series\n",
    "group by Country_Region\n",
    "order by largest_daily_cases DESC\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write a query that is able to find the dates when daily cases for each country exceed 10000 in `time_series`. Sorting the result with descending order.\n",
    "\n",
    "- Expected inputs：a query string.\n",
    "- Expected outputs：a (2273, 3) result.\n",
    "\n",
    "```\n",
    "      Country_Region        Date  daily_cases_by_country\n",
    "0             Turkey  2020-12-10                  823225\n",
    "1                 US  2021-01-02                  300416\n",
    "2                 US  2021-01-08                  293247\n",
    "3                 US  2021-01-07                  278065\n",
    "4                 US  2021-01-09                  262657\n",
    "...              ...         ...                     ...\n",
    "2268  United Kingdom  2021-02-25                   10020\n",
    "2269           Italy  2020-10-16                   10009\n",
    "2270    South Africa  2020-12-16                   10008\n",
    "2271          Mexico  2021-01-10                   10003\n",
    "2272     Switzerland  2020-12-21                   10002\n",
    "\n",
    "[2273 rows x 3 columns]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_large_daily_case_by_country_in_time_series =\\\n",
    "\"\"\"\n",
    "-- BEGIN SOLUTION\n",
    "select Country_Region, Date, Sum(daily_cases) AS daily_cases_by_country\n",
    "from time_series\n",
    "group by DATE, Country_Region\n",
    "having daily_cases_by_country > 10000\n",
    "order by daily_cases_by_country DESC\n",
    "-- END SOLUTION\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Run tests！\n",
    "\n",
    "Kernel -> Restart & Run All."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_01_select_all_from_daily_report (__main__.TestHomeworkTwo) ... ok\n",
      "test_02_select_variables_from_daily_report (__main__.TestHomeworkTwo) ... ok\n",
      "test_03_find_taiwan_from_time_series (__main__.TestHomeworkTwo) ... ok\n",
      "test_04_find_taiwan_plus_zero_from_time_series (__main__.TestHomeworkTwo) ... ok\n",
      "test_05_find_us_from_daily_report (__main__.TestHomeworkTwo) ... ok\n",
      "test_06_find_us_from_lookup_table (__main__.TestHomeworkTwo) ... ok\n",
      "test_07_aggregate_totals_from_daily_report (__main__.TestHomeworkTwo) ... ok\n",
      "test_08_find_countries_with_province_records_in_time_series (__main__.TestHomeworkTwo) ... ok\n",
      "test_09_find_largest_daily_case_by_country_in_time_series (__main__.TestHomeworkTwo) ... ok\n",
      "test_10_find_large_daily_case_by_country_in_time_series (__main__.TestHomeworkTwo) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 10 tests in 0.412s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestHomeworkTwo(unittest.TestCase):\n",
    "    def test_01_select_all_from_daily_report(self):\n",
    "        all_from_daily_report = pd.read_sql(select_all_from_daily_report, conn)\n",
    "        self.assertEqual(all_from_daily_report.shape, (3981, 7))\n",
    "    def test_02_select_variables_from_daily_report(self):\n",
    "        variables_from_daily_report = pd.read_sql(select_variables_from_daily_report, conn)\n",
    "        self.assertEqual(variables_from_daily_report.shape, (3981, 4))\n",
    "        np.testing.assert_equal(variables_from_daily_report.columns,\n",
    "                               np.array(['Combined_Key', 'Confirmed', 'Deaths', 'Recovered']))\n",
    "    def test_03_find_taiwan_from_time_series(self):\n",
    "        taiwan_from_time_series = pd.read_sql(find_taiwan_from_time_series, conn)\n",
    "        self.assertEqual(taiwan_from_time_series.shape, (404, 7))\n",
    "        np.testing.assert_equal(taiwan_from_time_series['Country_Region'].unique(),\n",
    "                               np.array(['Taiwan']))\n",
    "    def test_04_find_taiwan_plus_zero_from_time_series(self):\n",
    "        taiwan_plus_zero_from_time_series = pd.read_sql(find_taiwan_plus_zero_from_time_series, conn)\n",
    "        self.assertEqual(taiwan_plus_zero_from_time_series.shape, (162, 3))\n",
    "        np.testing.assert_equal(taiwan_plus_zero_from_time_series.columns,\n",
    "                               np.array(['Country_Region', 'Date', 'Daily_Cases']))\n",
    "        np.testing.assert_equal(taiwan_plus_zero_from_time_series['Daily_Cases'].sum(), 0)\n",
    "    def test_05_find_us_from_daily_report(self):\n",
    "        us_from_daily_report = pd.read_sql(find_us_from_daily_report, conn)\n",
    "        self.assertEqual(us_from_daily_report.shape, (3274, 3))\n",
    "        np.testing.assert_equal(us_from_daily_report.columns,\n",
    "                               np.array(['Combined_Key', 'Confirmed', 'Deaths']))\n",
    "    def test_06_find_us_from_lookup_table(self):\n",
    "        us_from_lookup_table = pd.read_sql(find_us_from_lookup_table, conn)\n",
    "        self.assertEqual(us_from_lookup_table.shape, (3404, 10))\n",
    "        np.testing.assert_equal(us_from_lookup_table['Country_Region'].unique(),\n",
    "                               'US')\n",
    "    def test_07_aggregate_totals_from_daily_report(self):\n",
    "        totals_from_daily_report = pd.read_sql(aggregate_totals_from_daily_report, conn)\n",
    "        self.assertEqual(totals_from_daily_report.shape, (1, 3))\n",
    "        np.testing.assert_equal(totals_from_daily_report.columns,\n",
    "                               np.array(['total_confirmed', 'total_deaths', 'total_recovered']))\n",
    "    def test_08_find_countries_with_province_records_in_time_series(self):\n",
    "        countries_with_province_records_in_time_series = pd.read_sql(find_countries_with_province_records_in_time_series, conn)\n",
    "        self.assertEqual(countries_with_province_records_in_time_series.shape, (7, 1))\n",
    "        superset = set(countries_with_province_records_in_time_series.values.ravel())\n",
    "        self.assertTrue({'Australia', 'Canada', 'Denmark', 'Netherlands'}.issubset(superset))\n",
    "    def test_09_find_largest_daily_case_by_country_in_time_series(self):\n",
    "        largest_daily_case_by_country_in_time_series = pd.read_sql(find_largest_daily_case_by_country_in_time_series, conn)\n",
    "        self.assertEqual(largest_daily_case_by_country_in_time_series.shape, (192, 3))\n",
    "        np.testing.assert_equal(largest_daily_case_by_country_in_time_series['Country_Region'].values[:5],\n",
    "                        np.array(['Turkey', 'US', 'France', 'India', 'Spain']))\n",
    "    def test_10_find_large_daily_case_by_country_in_time_series(self):\n",
    "        large_daily_case_by_country_in_time_series = pd.read_sql(find_large_daily_case_by_country_in_time_series, conn)\n",
    "        self.assertEqual(large_daily_case_by_country_in_time_series.shape, (2273, 3))\n",
    "        np.testing.assert_equal(large_daily_case_by_country_in_time_series['Country_Region'].values[:5],\n",
    "                        np.array(['Turkey', 'US', 'US', 'US', 'US']))\n",
    "        \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(TestHomeworkTwo)\n",
    "runner = unittest.TextTestRunner(verbosity=2)\n",
    "test_results = runner.run(suite)\n",
    "number_of_failures = len(test_results.failures)\n",
    "number_of_errors = len(test_results.errors)\n",
    "number_of_test_runs = test_results.testsRun\n",
    "number_of_successes = number_of_test_runs - (number_of_failures + number_of_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You've got 10 successes among 10 questions.\n"
     ]
    }
   ],
   "source": [
    "print(\"You've got {} successes among {} questions.\".format(number_of_successes, number_of_test_runs))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
